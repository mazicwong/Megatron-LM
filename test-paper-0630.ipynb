{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c48a4b2a",
   "metadata": {},
   "source": [
    "### first, why X@A can be splitted into [XA1, XA2] where we partition the A in the column parallel fashion. [1]\n",
    "\n",
    "[1] Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d3d44f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.randn(2, 5)\n",
    "a = torch.randn(5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "972c919c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xa1 = x@a[:,:10]\n",
    "xa2 = x@a[:,10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c6d528b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 20]), torch.Size([2, 10]), torch.Size([2, 10]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x@a).shape, xa1.shape, xa2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d565970",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# thus, in x@a, a can be partitioned in column. It is similar to the FFN neurons' parallels claim in DynaBERT\n",
    "x@a == torch.cat((xa1, xa2), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "78e805f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False,  True,  True,  True,  True, False,\n",
       "          True, False,  True, False,  True, False, False,  True, False, False],\n",
       "        [ True,  True,  True, False,  True, False, False,  True, False, False,\n",
       "          True, False,  True, False, False,  True, False, False,  True,  True]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in x@a, a is linear transformation, thus a can be partitioned and x can not.\n",
    "torch.concat((x[:1, :] @ a, x[1:, :] @ a), dim = 0) == x@a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e32ab591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3176284730434418\n",
      "0.3176284730434418\n",
      "0.3176284432411194\n",
      "0.3176284730434418\n"
     ]
    }
   ],
   "source": [
    "# todo. 费解的地方，为什么x@a中，拆开a没有精度问题，拆开x会有\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "print(float(x.matmul(a)[0][0]))\n",
    "print(float((x@a)[0][0]))\n",
    "print(float(torch.concat((x[:1,:]@a,x[1:,:]@a),dim=0)[0][0]))\n",
    "print(float(torch.concat((x@a[:,:1],x@a[:,1:]),dim=-1)[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56a1d0a",
   "metadata": {},
   "source": [
    "### how about adding gelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8ce2979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gelu(x):\n",
    "#     '''\n",
    "#     Two way to implements GELU, torch.nn use the second one:\n",
    "#     0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "#     or\n",
    "#     0.5 * x * (1. + torch.erf(torch.sqrt(x, 2))) \n",
    "#     '''\n",
    "#     return .5 * x * (1. + torch.erf(x / math.sqrt(2.)))\n",
    "gelu = torch.nn.GELU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cb5fec3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gelu(xa1 + xa2) != gelu(xa1) + gelu(xa2)\n",
    "# because gelu is non-linear, its output depends on all x\n",
    "gelu(xa1) + gelu(xa2) != gelu(xa1 + xa2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "871588bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gelu()\n",
    "torch.cat((gelu(xa1), gelu(xa2)), dim=-1) == gelu(x@a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6e5bfa",
   "metadata": {},
   "source": [
    "# Conclutions\n",
    "- x@a 的本质，想象x是seq，a是线性变换，x有很多行，a有很多列，其实就是对seq的每一行施加线性变换，让seq的每一行变长；\n",
    "- 在这个过程中，a是可以按列拆分的，之后再AllReduce还原回来，但是x由于需要过non-linear，所以不能按行拆分；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3b8465",
   "metadata": {},
   "source": [
    "# Future\n",
    "- consider bias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
